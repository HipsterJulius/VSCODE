{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden des Modells und des Tokenizers\n",
    "model_name = \"Helsinki-NLP/opus-mt-de-nl\"\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Text, den Sie übersetzen möchten\n",
    "german_text = \"Ich liebe dich\"\n",
    "\n",
    "# Tokenisieren und übersetzen\n",
    "inputs = tokenizer(german_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "outputs = model.generate(**inputs)\n",
    "\n",
    "# Die generierten Ausgaben decodieren\n",
    "translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"..\\out\\data.csv\",low_memory=False)\n",
    "selected_columns = ['category_de', 'name_de', 'algorithmus', 'description', 'statistical_basis']\n",
    "data = pd.concat([data[col] for col in selected_columns], axis=1)\n",
    "\n",
    "data = data.assign(\n",
    "    category_de=data['category_de'],\n",
    "    name_de=data['name_de'],\n",
    "    algorithmus=data['algorithmus'],\n",
    "    description=data['description'],\n",
    "    statistical_basis=data['statistical_basis'],\n",
    "    category_nl = \"\",\n",
    "    name_nl = \"\",\n",
    "    algorithmus_nl=\"\",\n",
    "    description_nl=\"\",\n",
    "    statistical_basis_nl=\"\",\n",
    "    )\n",
    "\n",
    "column_order = ['category_de','name_de', \"algorithmus\", \"description\", \"statistical_basis\", 'category_nl', 'name_nl', \"algorithmus_nl\", \"description_nl\", \"statistical_basis_nl\"]\n",
    "data = data[column_order]\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in data.index:\n",
    "    category_de = data['category_de'][index]\n",
    "    input_ids = tokenizer.encode(category_de, return_tensors=\"pt\")\n",
    "    output = model.generate(input_ids)\n",
    "    translation = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    data['category_nl'][index] = translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in data.index:\n",
    "    category_de = data['name_de'][index]\n",
    "    input_ids = tokenizer.encode(category_de, return_tensors=\"pt\")\n",
    "    output = model.generate(input_ids)\n",
    "    translation = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    data['name_nl'][index] = translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in data.index:\n",
    "    category_de = data['algorithmus'][index]\n",
    "    \n",
    "    if(type(category_de) == str):\n",
    "        input_ids = tokenizer.encode(category_de, return_tensors=\"pt\")\n",
    "        output = model.generate(input_ids)\n",
    "        translation = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        data['algorithmus_nl'][index] = translation\n",
    "    else: \n",
    "        data['algorithmus_nl'][index] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in data.index:\n",
    "    category_de = data['description'][index]\n",
    "    print(index)\n",
    "    if(type(category_de) == str):\n",
    "        input_ids = tokenizer.encode(category_de, return_tensors=\"pt\")\n",
    "        output = model.generate(input_ids)\n",
    "        translation = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        data['description_nl'][index] = translation\n",
    "    else: \n",
    "        data['description_nl'][index] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in data.index:\n",
    "    category_de = data['statistical_basis'][index]\n",
    "    print(index)\n",
    "    if(type(category_de) == str):\n",
    "        input_ids = tokenizer.encode(category_de, return_tensors=\"pt\")\n",
    "        output = model.generate(input_ids)\n",
    "        translation = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        data['statistical_basis_nl'][index] = translation\n",
    "    else: \n",
    "        data['statistical_basis_nl'][index] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n",
    "data.to_csv(\"C:/Users/juliu/VSCODE/VSCODE/inkar-indicators/src/model_translator/de_nl.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
